{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Pipeline: Computing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "repo_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(repo_path)\n",
    "\n",
    "import torch\n",
    "import warnings\n",
    "import polars as pl\n",
    "\n",
    "from pprint import pprint\n",
    "from loguru import logger\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Config\n",
    "from recsys.config import settings\n",
    "\n",
    "# BigQuery\n",
    "from recsys.gcp.bigquery import client as bq_client\n",
    "\n",
    "# Feature Store\n",
    "from recsys.gcp.feature_store import client as fs_client\n",
    "\n",
    "# Features\n",
    "from recsys.core.features.article_features import (\n",
    "    compute_features_articles,\n",
    "    generate_embeddings_for_dataframe,\n",
    ")\n",
    "from recsys.core.features.ranking_features import compute_rankings_dataset\n",
    "from recsys.core.features.customer_features import (\n",
    "    DatasetSampler,\n",
    "    compute_features_customers,\n",
    ")\n",
    "from recsys.core.features.interaction_features import generate_interaction_data\n",
    "from recsys.core.features.transaction_features import compute_features_transactions\n",
    "\n",
    "# Raw Data\n",
    "from recsys.data.sources import h_and_m_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONLINE: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóÑÔ∏è Articles data\n",
    "\n",
    "The **article_id** and **product_code** serve different purposes in the context of H&M's product database:\n",
    "\n",
    "- **Article ID**: This is a unique identifier assigned to each individual article within the database. It is typically used for internal tracking and management purposes. Each distinct item or variant of a product (e.g., different sizes or colors) would have its own unique article_id.\n",
    "\n",
    "- **Product Code**: This is also a unique identifier, but it is associated with a specific product or style rather than individual articles. It represents a broader category or type of product within H&M's inventory. Multiple articles may share the same product code if they belong to the same product line or style.\n",
    "\n",
    "While both are unique identifiers, the article_id is specific to individual items, whereas the product_code represents a broader category or style of product.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "**Product: Basic T-Shirt**\n",
    "\n",
    "- **Product Code:** TS001\n",
    "\n",
    "- **Article IDs:**\n",
    "    - Article ID: 1001 (Size: Small, Color: White)\n",
    "    - Article ID: 1002 (Size: Medium, Color: White)\n",
    "    - Article ID: 1003 (Size: Large, Color: White)\n",
    "    - Article ID: 1004 (Size: Small, Color: Black)\n",
    "    - Article ID: 1005 (Size: Medium, Color: Black)\n",
    "\n",
    "In this example, \"TS001\" is the product code for the basic t-shirt style. Each variant of this t-shirt (e.g., different sizes and colors) has its own unique article_id.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ONLINE:\n",
    "    articles_df = h_and_m_data.extract_articles_df()\n",
    "else:\n",
    "    articles_df = pl.read_csv(source=f\"{repo_path}/data/articles.csv\")\n",
    "\n",
    "articles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = compute_features_articles(articles_df, ONLINE, repo_path)\n",
    "articles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings from the articles description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, desc in enumerate(articles_df[\"article_description\"].head(n=3)):\n",
    "    logger.info(f\"Item {i + 1}:\\n{desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    f\"Loading ${settings.FEATURES_EMBEDDING_MODEL_ID} embedding model to {device=}\"\n",
    ")\n",
    "\n",
    "# Load embedding model from SentenceTransformers model registry\n",
    "model = SentenceTransformer(settings.FEATURES_EMBEDDING_MODEL_ID, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = generate_embeddings_for_dataframe(\n",
    "    articles_df, \"article_description\", model, batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each article description, we have a numerical vector which we can feed to a model, opposite to a string containing the description of an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df[[\"article_description\", \"embeddings\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df[\"image_url\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "image_urls = articles_df[\"image_url\"].tail(12).to_list()\n",
    "grid_html = '<div style=\"display: grid; grid-template-columns: repeat(6, 1fr); gap: 10pxl max-width: 900px;\">'\n",
    "\n",
    "for url in image_urls:\n",
    "    grid_html += f'<img src=\"{url}\" style=\"width: 100%; height: auto;\">'\n",
    "\n",
    "grid_html += \"</div>\"\n",
    "\n",
    "display(HTML(grid_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üëØ‚Äç‚ôÄÔ∏è Customers Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ONLINE:\n",
    "    customers_df = h_and_m_data.extract_customers_df()\n",
    "else:\n",
    "    customers_df = pl.read_csv(source=f\"{repo_path}/data/customers.csv\")\n",
    "\n",
    "customers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customers feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = compute_features_customers(customers_df, drop_null_age=True)\n",
    "customers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßæ Transactions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ONLINE:\n",
    "    transactions_df = h_and_m_data.extract_transactions_df()\n",
    "else:\n",
    "    transactions_df = pl.read_csv(source=f\"{repo_path}/data/transactions_train.csv\")\n",
    "\n",
    "transactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df[\"t_dat\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = compute_features_transactions(transactions_df, ONLINE)\n",
    "transactions_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time of the year a purchase was made should be a strong predictor, as seasonality plays a big factor in fashion purchases. Here, you will use the month of the purchase as a feature. Since this is a cyclical feature (January is as close to December as it is to February), you'll map each month to the unit circle using sine and cosine.\n",
    "\n",
    "Thus, the features of the transactions DataFrame look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to work with ~30 million transactions in these series, as everything will take too much time to run. Thus, we create a subset of the original dataset by randomly sampling from the customers' datasets and taking only their transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DatasetSampler(size=settings.CUSTOMER_DATA_SIZE)\n",
    "\n",
    "dataset_subset = sampler.sample(\n",
    "    customers_df=customers_df, transactions_df=transactions_df\n",
    ")\n",
    "\n",
    "customers_df = dataset_subset[\"customers\"]\n",
    "transactions_df = dataset_subset[\"transactions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the remaining customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_id in transactions_df[\"customer_id\"].unique().head(10):\n",
    "    logger.info(f\"Logging customer ID: {customer_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§≥üèª Interaction data\n",
    "\n",
    "To train our models, we need more than just the transactions DataFrame. We need positive samples that signal whether a customer clicked or bought an item, but we also need negative samples that signal no interactions between a customer and an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df = generate_interaction_data(transactions_df)\n",
    "interaction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what each score means:\n",
    "- `0` : No interaction between a customer and an item\n",
    "- `1` : A customer clicked an item\n",
    "- `2` : A customer bought an item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df.group_by(\"interaction_score\").agg(\n",
    "    pl.count(\"interaction_score\").alias(\"total_interactions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload feature group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys.config import settings\n",
    "print(settings.BIGQUERY_DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Uploading 'customers' Feature to BigQuery.\")\n",
    "bq_client.load_features(customers_df=customers_df)\n",
    "logger.info(\"‚úÖ Uploaded 'customers' Feature to BigQuery!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.collect_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Uploading 'articles' Feature to BigQuery.\")\n",
    "bq_client.load_features(articles_df=articles_df)\n",
    "logger.info(\"‚úÖ Uploaded 'articles' Feature to BigQuery!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Uploading 'transactions' Feature to BigQuery.\")\n",
    "bq_client.load_features(transactions_df=transactions_df)\n",
    "logger.info(\"‚úÖ Uploaded 'transactions' Feature to BigQuery!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Uploading 'interactions' Feature to BigQuery.\")\n",
    "bq_client.load_features(interactions_df=interaction_df)\n",
    "logger.info(\"‚úÖ Uploaded 'interactions' Feature to BigQuery!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ranking dataset\n",
    "\n",
    "The last step is to compute the ranking dataset used to train the scoring/ranking model from the feature groups we've just created:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_client.initialize()\n",
    "fos = fs_client.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fv, articles_fv, customers_fv, _ = fs_client.get_feature_views(fos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "ranking_df = compute_rankings_dataset(trans_fv, articles_fv, customers_fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df.get_column(\"label\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"customer_id\",\n",
    "    \"age\",\n",
    "    \"article_id\",\n",
    "    \"label\",\n",
    "    \"product_type_name\",\n",
    "    \"product_group_name\",\n",
    "    \"graphical_appearance_name\",\n",
    "    \"colour_group_name\",\n",
    "    \"perceived_colour_value_name\",\n",
    "    \"perceived_colour_master_name\",\n",
    "    \"department_name\",\n",
    "    \"index_name\",\n",
    "    \"index_group_name\",\n",
    "    \"section_name\",\n",
    "    \"garment_group_name\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ranking_df = ranking_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the ranking dataset was computed based on articles, customers, and transactions Feature Views, we can reflect this lineage in the ranking Feature View."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Uploading 'rankings' Feature to BigQuery.\")\n",
    "bq_client.load_features(rankings_df=filtered_ranking_df)\n",
    "logger.info(\"‚úÖ Uploaded 'rankings' Feature to BigQuery!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
