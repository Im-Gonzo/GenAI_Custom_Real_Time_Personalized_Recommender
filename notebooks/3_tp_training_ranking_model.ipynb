{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Training pipeline: Training ranking model </span>\n",
    "\n",
    "In this notebook, you will train a ranking model using gradient boosted trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import polars as pl\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from recsys.config import settings\n",
    "from recsys.data.preprocessing.splitting import train_test_split\n",
    "from recsys.gcp.vertex_ai.serving.ranking import GCPRankingModel\n",
    "from recsys.core.models.two_tower.ranking import (\n",
    "    RankingModelFactory,\n",
    "    RankingModelTrainer,\n",
    ")\n",
    "from recsys.gcp.feature_store import client as fs_client\n",
    "from recsys.gcp.bigquery import client as bq_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíø Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()[:-9]\n",
    "fullpath = os.path.join(path, 'data/preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = pl.read_csv(f'{fullpath}/transactions.csv')\n",
    "articles_df = pl.read_parquet(f'{fullpath}/articles.parquet')\n",
    "customers_df = pl.read_csv(f'{fullpath}/customers.csv')\n",
    "rankings_df = pl.read_csv(f'{fullpath}/ranking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_df = rankings_df.join(\n",
    "    trans_df.select([\"customer_id\", \"month_sin\", \"month_cos\"]),\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = articles_df.with_columns(pl.col('article_id').cast(pl.Int64))\n",
    "\n",
    "rankings_df = rankings_df.join(\n",
    "    articles_df.select([\"article_id\", \"colour_group_name\"]),\n",
    "    on=\"article_id\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_df = rankings_df.drop(\"customer_id\", \"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df=rankings_df,\n",
    "    test_size=settings.RANKING_DATASET_VALIDATION_SPLIT_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the ranking model\n",
    "\n",
    "Let's train the ranking model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RankingModelFactory.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RankingModelTrainer(\n",
    "    model=model, train_dataset=(X_train, y_train), eval_dataset=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold, best_metrics = trainer.find_optimal_threshold(step=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the ranking model\n",
    "\n",
    "Next, you'll evaluate how well the model performs on the validation data using metrics for classification such as precision, recall and f1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(log=True, threshold=optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the model has a low F1-score on the positive class (higher is better). The performance could potentially be improved by adding more features to the dataset, e.g. image embeddings.\n",
    "\n",
    "Let's see which features your model considers important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóÑÔ∏è Save model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_model_gcp = GCPRankingModel(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_model_gcp.save_to_local('ranking_model/ranking')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
